# Personalized Product Recommendation Narratives with a 60M-parameter Small Language Model

**From-scratch SLM + LoRA + RAG for engaging, low-cost, privacy-friendly e-commerce recommendations**

![Project Banner / Demo GIF Placeholder]
*(Add a short GIF or screenshot here later â€“ e.g., Streamlit UI showing input â†’ generated narrative)*

## ğŸ¯ Project Goal

Build an **end-to-end, portfolio-grade ML project** that demonstrates:

- Training a Small Language Model (~50â€“60M parameters) from scratch (inspired by nanoGPT)
- Efficient fine-tuning with LoRA and quantization
- Retrieval-Augmented Generation (RAG) for factual, up-to-date recommendations
- Personalized narrative generation for e-commerce (beyond simple "you might like X")
- Full ML engineering spectrum: data â†’ modeling â†’ evaluation â†’ production â†’ MLOps

The model generates **coherent, engaging recommendation text** like:

> "You've loved our bold single-origin coffees in the past â€” especially that bright Ethiopian roast. For your next morning brew, try this new Guatemalan Finca El Platanillo: deep chocolate notes with a hint of red berry, perfectly balanced for pour-over. Currently 20% off â€” pairs beautifully with your favorite oat milk!"

...while grounding recommendations in real product data via RAG, all running efficiently on modest hardware.

## Why This Matters (2025â€“2026 Context)

- Massive LLMs (70B+) are expensive and slow for real-time personalization at scale
- Small models + PEFT + RAG offer **sub-second inference**, **low carbon footprint**, and **on-device potential**
- Narrative recommendations outperform list-based ones in user engagement & conversion (industry studies 2024â€“2025)
- Privacy: keep user history local, only send minimal query to server

## Key Features / Techniques Demonstrated

- Decoder-only Transformer built from scratch (causal self-attention, rotary? no â€” learned positional)
- Efficient training on memmapped binaries (Tiktoken + GPT-2 vocab)
- Parameter-efficient fine-tuning with LoRA (rank 16â€“32)
- 8-bit / 4-bit quantization (bitsandbytes)
- FAISS-based RAG retriever over product embeddings
- Controlled generation (temperature, top-k, repetition penalty)
- Experiment tracking with MLflow
- FastAPI backend + Streamlit interactive demo
- Docker support for easy deployment
- Bias & fairness checks on recommendations

## Repository Structure

personalized-recommendation-narratives-slm/
â”‚
â”œâ”€â”€ README.md                     â† main entry point, project overview, demo GIF/video link, setup instructions
â”‚
â”œâ”€â”€ requirements.txt              â† pinned dependencies
â”œâ”€â”€ setup.py                      â† optional, if we want to make it installable
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_project_overview_and_motivation.ipynb
â”‚   â”œâ”€â”€ 02_data_exploration_and_preparation.ipynb
â”‚   â”œâ”€â”€ 03_slm_architecture_from_scratch.ipynb          â† heavily based on your original notebook + explanations
â”‚   â”œâ”€â”€ 04_adding_lora_and_quantization.ipynb
â”‚   â”œâ”€â”€ 05_building_rag_retriever.ipynb
â”‚   â”œâ”€â”€ 06_fine_tuning_and_experiment_tracking.ipynb
â”‚   â”œâ”€â”€ 07_evaluation_and_quality_assessment.ipynb
â”‚   â””â”€â”€ 08_inference_examples_and_controlled_generation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py               â† custom Dataset + collate_fn
â”‚   â”‚   â”œâ”€â”€ preprocessing.py         â† tokenization, prompt templates, memmap helpers
â”‚   â”‚   â””â”€â”€ rag_retriever.py         â† FAISS index builder + search logic
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gpt.py                   â† core GPT architecture (from your notebook + modifications)
â”‚   â”‚   â”œâ”€â”€ lora.py                  â† LoRA wrappers / injection logic
â”‚   â”‚   â””â”€â”€ utils.py                 â† init weights, generation helpers, KV cache
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py               â† training loop, logging, checkpointing
â”‚   â”‚   â””â”€â”€ evaluate.py              â† metrics computation
â”‚   â”‚
â”‚   â””â”€â”€ inference/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ generator.py             â† high-level recommendation generation with RAG
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                      â† FastAPI backend
â”‚   â”œâ”€â”€ streamlit_app.py             â† frontend demo
â”‚   â””â”€â”€ utils.py                     â† API helpers
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ base.yaml                    â† hydra-style config (model, training, data)
â”‚   â””â”€â”€ inference.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_data.py             â† helper to download + subsample HF datasets
â”‚   â”œâ”€â”€ prepare_data.py              â† creates .bin files
â”‚   â”œâ”€â”€ train.py                     â† entry point for training
â”‚   â””â”€â”€ generate_demo.py             â† example generations
â”‚
â”œâ”€â”€ mlruns/                          â† MLflow tracking folder (gitignored)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile
â””â”€â”€ docs/
    â””â”€â”€ architecture.md              â† mermaid diagrams, explanations