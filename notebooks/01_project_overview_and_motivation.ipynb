{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0818b945",
   "metadata": {},
   "source": [
    "# 01 - Project Overview & Motivation  \n",
    "Personalized Product Recommendation Narratives with a ~60M Parameter SLM\n",
    "\n",
    "**Author:** Abhishek  \n",
    "**Date:** January 2026  \n",
    "**Goal of this notebook:** Introduce the problem, business context, why small language models matter in 2026, and high-level architecture of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7169a",
   "metadata": {},
   "source": [
    "## 1. The Real Problem in E-commerce Personalization (2025–2026)\n",
    "\n",
    "Modern e-commerce platforms face three converging challenges:\n",
    "\n",
    "1. **User expectation explosion**  \n",
    "   Customers want hyper-personalized, trustworthy experiences — not just \"recommended products\", but **explanations and stories** that feel human.\n",
    "\n",
    "2. **Cost & latency explosion of large LLMs**  \n",
    "   GPT-4o, Claude 3.5, Llama-3.1-70B etc. are powerful but:\n",
    "   - Cost: $0.5–$15 per million tokens\n",
    "   - Latency: 1–5 seconds for narrative generation\n",
    "   - Privacy risk: user history sent to cloud\n",
    "\n",
    "3. **Cold-start & long-tail products**  \n",
    "   New items / new users suffer from lack of data → simple collaborative filtering fails.\n",
    "\n",
    "**Goal of this project:** Build a lightweight, efficient, **on-premise / edge-capable** solution that generates **coherent, engaging, grounded recommendation narratives** using only ~60M parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098c765",
   "metadata": {},
   "source": [
    "## 2. Why Small Language Models (SLMs) + RAG in 2026?\n",
    "\n",
    "| Approach                  | Pros                                      | Cons                                      | When it wins                          |\n",
    "|---------------------------|-------------------------------------------|-------------------------------------------|---------------------------------------|\n",
    "| Full 7B–70B LLM           | Strong zero-shot, world knowledge         | High cost, slow, privacy issues           | High-margin luxury / complex reasoning|\n",
    "| SLM (50–250M) from scratch| Fast, cheap, private, fine-tunable quickly| Limited general knowledge                 | Domain-specific + RAG                 |\n",
    "| SLM + LoRA + RAG          | Best of both: factual + fast + cheap      | Needs good retriever + prompt engineering | This project — e-commerce sweet spot  |\n",
    "\n",
    "Key insight 2025–2026:  \n",
    "**The future is not bigger models — it's smarter, smaller models with retrieval and efficient adaptation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a32564",
   "metadata": {},
   "source": [
    "## 3. What the Model Actually Does\n",
    "\n",
    "Input:\n",
    "- User profile (past purchases/reviews – text summary)\n",
    "- Current query or context (e.g. \"summer travel gadgets\")\n",
    "- Retrieved top-k products (via RAG)\n",
    "\n",
    "Output:\n",
    "A natural-language narrative recommendation, e.g.:\n",
    "\n",
    "> \"Based on your recent interest in lightweight travel backpacks and eco-friendly materials, I think you'll really appreciate the Patagonia Black Hole 25L. It's made from 100% recycled fabrics, weighs under 700g, and has that durable water-repellent coating you loved in your last Osprey. Right now it's on sale for ₹4,999 — perfect for your upcoming Goa trip!\"\n",
    "\n",
    "Grounded → no hallucinated products  \n",
    "Engaging → storytelling tone  \n",
    "Personalized → references user history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828685cf",
   "metadata": {},
   "source": [
    "## 4. High-Level Architecture\n",
    "![Model Architecture](./../image/slm_recommendation_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ad580",
   "metadata": {},
   "source": [
    "\n",
    "**Cell 6 (Markdown)**\n",
    "\n",
    "```markdown\n",
    "## 5. Success Criteria for this Portfolio Project\n",
    "\n",
    "- Runs end-to-end on MacBook M-series (16–32 GB RAM)\n",
    "- Generates coherent narratives in <1 second (quantized)\n",
    "- Shows measurable improvement over baseline (random / popularity recs)\n",
    "- Clean code structure (notebooks for learning, src/ for production)\n",
    "- Includes bias/fairness checks\n",
    "- Deployable demo (Streamlit + FastAPI)\n",
    "\n",
    "Next notebook: Data exploration & preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c8f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 01 loaded successfully on your MacBook!\n",
      "PyTorch version: 2.10.0\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook 01 loaded successfully on your MacBook!\")\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c3c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
